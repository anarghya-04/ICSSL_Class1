{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/1rHSMVmZRqhjXmrkLIc3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anarghya-04/ICSSL/blob/main/ICSSL_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ICSSL NOTES"
      ],
      "metadata": {
        "id": "EvWqmTj0Nj7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BASICS"
      ],
      "metadata": {
        "id": "xWgApOzzeKMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y = f(X) + e\n",
        "\n",
        "\n",
        "*   X is the independent variable.\n",
        "*   Y is the dependent varable.\n",
        "*   e is the error term\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LV3s8f6rNs62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical learning refers to a set of approaches for estimating f.\n",
        "\n",
        "\n",
        "*   Parametric Method\n",
        "*   Non-Parametric Method\n",
        "\n"
      ],
      "metadata": {
        "id": "yy6H7MORODzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parametric Method (OLS)\n",
        "\n",
        "1.   We assume that the functional form is linear.\n",
        "2.   We then need to fit or train the model by estimating the values of the parametre.\n",
        "\n",
        "The estimated model becomes a poor estimate when it is far from the true model.\n",
        "\n",
        "Overfitting is when the model captures underlying patterns as well as the errors and ouliers closely.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QP9OFvWKP14n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-parametric method\n",
        "\n",
        "This method does not make explicit assumptions about the functional form of f. Instead it seeks an estimate of f that gets as close to the data points as possible without being too rough or wiggly. However, a large number of observations are required for this estimate."
      ],
      "metadata": {
        "id": "qcVF9rGhYdhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supervised Learning:\n",
        "*   Outcome/Output is known.\n",
        "*   Each value of Y can be mapped to a value of X.\n",
        "\n",
        "Unsupervised Learning:\n",
        "*   Outcome is unknown.\n",
        "*   The data forms clusters or structures automatically.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K5PnFJp3YzH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resampling Methods"
      ],
      "metadata": {
        "id": "9fI3JthTdwep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOOTSTRAPPING"
      ],
      "metadata": {
        "id": "bRJ7t1iPokhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a tool to quantify the uncertainty associated with a given estimator or statistical learning method.\n",
        "\n",
        "For example, it can be used to estimate the standard errors of the coefficients from a linear regression fit."
      ],
      "metadata": {
        "id": "4nGWzd_jeU4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bootstrapping resamples the original dataset with replacement to create many \"pseudo-datasets,\" mimicking new independent samples from the population without collecting fresh data.\n",
        "\n",
        "It estimates sampling distribution of a statistic (e.g., mean, median), enabling confidence intervals or standard errors without assuming normality. Ideal when population access is limited."
      ],
      "metadata": {
        "id": "xaBnDfiFexDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PERMUTATION\n",
        "\n",
        "Resamples group labels (e.g., treatment/control) without replacement by shuffling them across fixed observations.\n",
        "\n",
        "Tests null hypothesis of no group differences (e.g., independence), generating a distribution of test statistics under H0 for p-values."
      ],
      "metadata": {
        "id": "NBp_jr6cgo8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOMIZATION\n",
        "\n",
        "Resamples treatment assignments (group memberships) without replacement, preserving experimental design structure like blocks.\n",
        "\n",
        "Validates causal inference in randomized experiments by simulating the assignment mechanism under sharp null (no treatment effect). Computes p-values for treatment effects."
      ],
      "metadata": {
        "id": "RMTERAt_pT1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OPTIMIZATION"
      ],
      "metadata": {
        "id": "D9r1wb2tpdtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization means finding the best choice among many possibilities.\n",
        "\n",
        "In statistical learning, we optimize model settings so predictions are as close as possible to reality."
      ],
      "metadata": {
        "id": "vLr2ujHs5cN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss functions measure how bad our predictions are.\n",
        "\n",
        "*   Good predictions-> Small loss\n",
        "*   Bad predictions-> Large loss.\n",
        "\n",
        "So if want the model that best fits the data, we need to minimize the loss."
      ],
      "metadata": {
        "id": "uN_Js3IK5slb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convex functions: functions which have a single global minimum."
      ],
      "metadata": {
        "id": "AMex2bB46Bae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiple minima, the loss function gets minimised untill the local minima as starting point matters."
      ],
      "metadata": {
        "id": "vBprBRRy6Lsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LINEAR REGRESSION"
      ],
      "metadata": {
        "id": "E6ow8p399rnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R^2 = Coefficient of determination or the proportion of explained variance.\n",
        "\n",
        "RSS = Residual Sum of Squares\n",
        "\n",
        "TSS = Total Sum of Squares\n",
        "\n",
        "High R^2 = Low RSS (Minimal error and large proportion of variance explained.)"
      ],
      "metadata": {
        "id": "5RhQn392B8mm"
      }
    }
  ]
}